% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/feature_importance.R
\name{find_permuted_perf_metric}
\alias{find_permuted_perf_metric}
\title{Get permuted performance metric difference for a single feature (or group of features)}
\usage{
find_permuted_perf_metric(
  test_data,
  trained_model,
  outcome_colname,
  perf_metric_function,
  perf_metric_name,
  class_probs,
  feat,
  seed
)
}
\arguments{
\item{test_data}{held out test data: dataframe of outcome and features}

\item{trained_model}{trained model from caret}

\item{outcome_colname}{Column name as a string of the outcome variable (default \code{NULL}; will be chosen automatically).}

\item{perf_metric_function}{Function to calculate the performance metric to be used for cross-validation and test performance. Some functions are provided by caret (see \link[caret]{defaultSummary}). Defaults: binary classification = \code{twoClassSummary}, multi-class classification = \code{multiClassSummary}, regression = \code{defaultSummary}.}

\item{perf_metric_name}{The column name from the output of the function provided to perf_metric_function that is to be used as the performance metric. Defaults: binary classification = \code{"ROC"}, multi-class classification = \code{"logLoss"}, regression = \code{"RMSE"}.}

\item{class_probs}{whether to use class probabilities}

\item{feat}{feature or group of correlated features to permute}

\item{seed}{Random seed (default: \code{NA}). Your results will be reproducible if you set a seed.}
}
\value{
vector of mean permuted auc and mean difference between test and permuted auc
}
\description{
Requires the \code{future.apply} package
}
\author{
Begüm Topçuoğlu, \email{topcuoglu.begum@gmail.com}

Zena Lapp, \email{zenalapp@umich.edu}
}
