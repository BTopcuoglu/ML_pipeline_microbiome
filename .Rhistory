set.seed(0)
expect_equal(length(get_seeds_trainControl(2,2,2)), 2*2+1)
expect_equal(length(get_seeds_trainControl(2,2,3)[[1]]), 2)
get_seeds_trainControl(2,2,3) %>% dput()
test_that("get_seeds_trainControl works", {
set.seed(0)
expect_equal(length(get_seeds_trainControl(2,2,2)), 2*2+1)
expect_equal(length(get_seeds_trainControl(2,2,3)[[1]]), 2)
expect_equal(
get_seeds_trainControl(2,2,3),
list(c(277L, 874L), c(950L, 494L), c(330L, 775L), c(841L, 591L), 725L)
)
})
source('~/Desktop/mikRopML/data-raw/otu_small.R', echo=TRUE)
source('~/Desktop/mikRopML/data-raw/otu_medium.R', echo=TRUE)
devtools::load_all()
set.seed(0)
expect_equal(length(get_seeds_trainControl(2,2,2)), 2*2+1)
expect_equal(length(get_seeds_trainControl(2,2,3)[[1]]), 2)
get_seeds_trainControl(2,2,3) %>% dput()
devtools::load_all()
set.seed(0)
expect_equal(length(get_seeds_trainControl(2,2,2)), 2*2+1)
expect_equal(length(get_seeds_trainControl(2,2,3)[[1]]), 2)
get_seeds_trainControl(2,2,3) %>% dput()
test_that("get_seeds_trainControl works", {
set.seed(0)
expect_equal(length(get_seeds_trainControl(2,2,2)), 2*2+1)
expect_equal(length(get_seeds_trainControl(2,2,3)[[1]]), 2)
expect_equal(
get_seeds_trainControl(2,2,3),
list(c(330L, 1799L), c(1615L, 1749L), c(37L, 1129L), c(729L, 878L), 485L)
)
})
source('~/Desktop/mikRopML/data-raw/otu_mini.R', echo=TRUE)
get_seeds_trainControl(2,2,3)
get_seeds_trainControl(2,2,2)
otu_mini_cv5
## code to prepare `otu_mini_results`
otu_mini_results1 <- mikRopML::run_ml(otu_mini,
"regLogistic",
outcome_colname = "dx",
outcome_value = "cancer",
hyperparameters = mikRopML::test_hyperparams,
find_feature_importance = FALSE,
seed = 2019,
kfold = 2
)
otu_mini_results2 <- mikRopML::run_ml(otu_mini,
"rf",
outcome_colname = "dx",
outcome_value = "cancer",
hyperparameters = mikRopML::test_hyperparams,
find_feature_importance = FALSE,
seed = 2019,
kfold = 2
)
otu_mini_results3 <- mikRopML::run_ml(otu_mini,
"svmRadial",
outcome_colname = "dx",
outcome_value = "cancer",
hyperparameters = mikRopML::test_hyperparams,
find_feature_importance = FALSE,
seed = 2019,
kfold = 2
)
train_data_mini
ncol(train_data_mini)
get_seeds_trainControl(kfold = 2,times = 100,ncol_train = ncol(train_data_mini))
sapply(get_seeds_trainControl(kfold = 2,times = 100,ncol_train = ncol(train_data_mini)),length)
sapply((get_seeds_trainControl(2,2,3)),length)
expect_equal(sapply((get_seeds_trainControl(2,2,3)),length), c(rep(2,4),1))
source('~/Desktop/mikRopML/data-raw/otu_mini.R', echo=TRUE)
?caret::train
?caret::trainContro
?caret::trainControl
traceback()
otu_mini_cv5
otu_mini_results5 <- mikRopML::run_ml(otu_mini,
"xgbTree",
outcome_colname = "dx",
outcome_value = "cancer",
hyperparameters = mikRopML::test_hyperparams,
find_feature_importance = FALSE,
seed = 2019,
kfold = 2
)
source('~/Desktop/mikRopML/data-raw/otu_mini.R', echo=TRUE)
source('~/Desktop/mikRopML/data-raw/otu_small.R', echo=TRUE)
source('~/Desktop/mikRopML/data-raw/otu_medium.R', echo=TRUE)
devtools::test()
otu_mini_cv5 <- define_cv(train_data_mini,'dx',2,100,2019)
form <- stats::as.formula(paste(outcome_colname, "~ ."))
trained_model_mini <- caret::train(
form,
data = train_data_mini,
method = "regLogistic",
trControl = otu_mini_cv5,
metric = "ROC",
tuneGrid = grid,
family = "binomial"
)
usethis::use_data(otu_mini_cv5, overwrite = TRUE)
usethis::use_data(train_data_mini, overwrite = TRUE)
usethis::use_data(test_data_mini, overwrite = TRUE)
usethis::use_data(trained_model_mini, overwrite = TRUE)
otu_sm_cv5 <- define_cv(train_data_sm,'dx',2,100,2019)
trained_model_sm1 <- caret::train(
form,
data = train_data_sm,
method = "regLogistic",
trControl = otu_sm_cv5,
metric = "ROC",
tuneGrid = grid,
family = "binomial"
)
usethis::use_data(otu_sm_cv5, overwrite = TRUE)
usethis::use_data(train_data_sm, overwrite = TRUE)
usethis::use_data(test_data_sm, overwrite = TRUE)
usethis::use_data(trained_model_sm1, overwrite = TRUE)
options(warnPartialMatchArgs = FALSE)
predictions_sm <- c(
0.302553723266671, 0.21761199572356, 0.149449241881401, 0.0733187260761979,
0.275953437442721, 0.166145147735239, 0.275792077306705, 0.160381104457551,
0.311538843510942, 0.137316276051265, 0.118099504411304, 0.293299235679477
)
outcomes_sm <- c(0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0)
tol <- 1e-5
test_that("get_predictions works", {
expect_equal(get_predictions(trained_model_sm1, test_data_sm, "cancer"),
predictions_sm,
tolerance = tol
)
})
get_predictions(trained_model_sm1, test_data_sm, "cancer")
round(get_predictions(trained_model_sm1, test_data_sm, "cancer"))
round(get_predictions(trained_model_sm1, test_data_sm, "cancer"),2)
get_predictions(trained_model_sm1, test_data_sm, "cancer") %>% dput()
predictions_sm <- c(0.00916324268270163, 5.50247841835105e-06, 0.992924252456899,
7.99185706501504e-09, 0.497920659124481, 3.77475828372553e-15,
0.999862709044069, 2.15915501822206e-06, 1.78960513393944e-05,
0.0277499865819482, 1.74347802861519e-09, 0.856744054489971)
outcomes_sm <- c(0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0)
tol <- 1e-5
test_that("get_predictions works", {
expect_equal(get_predictions(trained_model_sm1, test_data_sm, "cancer"),
predictions_sm,
tolerance = tol
)
})
test_that("recode_outcome works", {
expect_equal(
recode_outcome(test_data_sm, "dx", "cancer"),
outcomes_sm
)
expect_equal(
recode_outcome(test_data_sm, "dx", "normal"),
c(1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1)
)
})
test_that("calc_auroc works", {
expect_equal(calc_auroc(predictions_sm, outcomes_sm), 0.7)
})
calc_auroc(predictions_sm, outcomes_sm)
test_that("calc_auroc works", {
expect_equal(calc_auroc(predictions_sm, outcomes_sm), 0.9)
})
test_that("calc_auprc works", {
expect_equal(calc_auprc(predictions_sm, outcomes_sm), 0.2337616,
tolerance = tol
)
})
calc_auprc(predictions_sm, outcomes_sm)
test_that("calc_auprc works", {
expect_equal(calc_auprc(predictions_sm, outcomes_sm), 0.7123179,
tolerance = tol
)
})
test_that("calc_aucs works", {
expect_equal(
calc_aucs(trained_model_sm1, test_data_sm, "dx", "cancer"),
list(auroc = 0.7, auprc = 0.2337616),
tolerance = tol
)
})
calc_aucs(trained_model_sm1, test_data_sm, "dx", "cancer")
test_that("calc_aucs works", {
expect_equal(
calc_aucs(trained_model_sm1, test_data_sm, "dx", "cancer"),
list(auroc = 0.9, auprc = 0.7123179),
tolerance = tol
)
})
devtools::test()
test_that("define_cv works for 5-fold cv on otu_sm data", {
expect_equal(
define_cv(train_data_sm, "dx", kfold = 5, seed = 2019),
otu_sm_cv5
)
})
test_that("define_cv works for 5-fold cv on otu_sm data", {
expect_equal(
define_cv(train_data_sm, "dx", kfold = 2, seed = 2019),
otu_sm_cv5
)
})
test_that("get_seeds_trainControl works", {
set.seed(0)
expect_equal(length(get_seeds_trainControl(2,2,2)), 2*2+1)
expect_equal(sapply((get_seeds_trainControl(2,2,3)),length), c(rep(2,4),1))
expect_equal(
get_seeds_trainControl(2,2,3),
list(c(330L, 1799L), c(1615L, 1749L), c(37L, 1129L), c(729L, 878L), 485L)
)
})
devtools::test()
# tests for functions in get_features_importance
# group_correlated_features
test_that("correlated groups correct", {
corr <- dplyr::tibble(
feature1 = c("A", "C", "D"),
feature2 = c("B", "A", "E")
)
test_data <- dplyr::tibble(
inf = NA,
A = NA,
B = NA,
C = NA,
D = NA,
E = NA,
F = NA
)
expect_equal(sort(group_correlated_features(corr, test_data)), c("B|A|C", "E|D", "F"))
})
# tests for functions in get_features_importance
# group_correlated_features
test_that("correlated groups correct", {
corr <- dplyr::tibble(
feature1 = c("A", "C", "D"),
feature2 = c("B", "A", "E")
)
test_data <- dplyr::tibble(
inf = NA,
A = NA,
B = NA,
C = NA,
D = NA,
E = NA,
F = NA
)
expect_equal(sort(group_correlated_features(corr, test_data)), c("B|A|C", "E|D", "F"))
})
test_that("no correlated groups correct", {
corr <- dplyr::tibble(feature1 = c(character()), feature2 = character())
test_data <- dplyr::tibble(
inf = NA,
A = NA,
B = NA,
C = NA,
D = NA,
E = NA,
F = NA
)
expect_equal(
sort(group_correlated_features(corr, test_data)),
c("A", "B", "C", "D", "E", "F")
)
})
test_that("empty dataframe correct", {
corr <- dplyr::tibble(feature1 = c(character()), feature2 = character())
test_data <- dplyr::tibble()
expect_equal(sort(group_correlated_features(corr, test_data)), c("NA", "NA"))
})
# find_permuted_auc
test_that("permuted auc returns correct value for non-correlated feature", {
expect_equal(
find_permuted_auc(trained_model_sm1, test_data_sm, "dx", "Otu00049", "cancer"),
c(auc = 0.7075, auc_diff = -0.0075)
)
})
test_that("permuted auc returns correct value for [fake] correlated feature", {
expect_equal(find_permuted_auc(
trained_model_sm1,
test_data_sm,
"dx",
"Otu00049|Otu00050",
"cancer"
),
c(auc = 0.71, auc_diff = -0.01))
})
find_permuted_auc(
trained_model_sm1,
test_data_sm,
"dx",
"Otu00049|Otu00050",
"cancer"
)
# find_permuted_auc
test_that("permuted auc returns correct value for non-correlated feature", {
expect_equal(
find_permuted_auc(trained_model_sm1, test_data_sm, "dx", "Otu00049", "cancer"),
c(auc = 0.7075, auc_diff = -0.0075)
)
})
find_permuted_auc(trained_model_sm1, test_data_sm, "dx", "Otu00049", "cancer")
# find_permuted_auc
test_that("permuted auc returns correct value for non-correlated feature", {
expect_equal(
find_permuted_auc(trained_model_sm1, test_data_sm, "dx", "Otu00049", "cancer"),
c(auc = 0.9, auc_diff = 0.0)
)
})
test_that("permuted auc returns correct value for [fake] correlated feature", {
expect_equal(find_permuted_auc(
trained_model_sm1,
test_data_sm,
"dx",
"Otu00049|Otu00050",
"cancer"
),
c(auc = 0.9, auc_diff = 0.0))
})
feat_imps <- structure(list(
auc = c(
0.7065, 0.8155, 0.708, 0.71, 0.744, 0.7,
0.7755, 0.728, 0.784, 0.7285, 0.735, 0.7755, 0.7005, 0.8085,
0.7, 0.7325, 0.7105, 0.7, 0.8585, 0.7055, 0.7235, 0.7, 0.7, 0.7,
0.7035, 0.716, 0.7, 0.863, 0.7, 0.7065, 0.7, 0.7, 0.702, 0.599,
0.7165, 0.7655, 0.7, 0.703, 0.7, 0.7, 0.7, 0.7025, 0.7, 0.7,
0.7, 0.7, 0.7, 0.7145, 0.7075, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,
0.7, 0.7, 0.7, 0.7, 0.7
),
auc_diff = c(
-0.00650000000000005,
-0.1155, -0.00800000000000001, -0.01, -0.044, 0, -0.0755, -0.028,
-0.084, -0.0285, -0.035, -0.0755000000000001, -5e-04, -0.1085,
0, -0.0325, -0.0105, 0, -0.1585, -0.00550000000000002, -0.0235,
0, 0, 0, -0.0035, -0.016, 0, -0.163, 0, -0.00650000000000001,
0, 0, -0.002, 0.101, -0.0165, -0.0655, 0, -0.003, 0, 0, 0, -0.0025,
0, 0, 0, 0, 0, -0.0145, -0.00750000000000001, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0
),
names = structure(1:60,
.Label = c(
"Otu00001",
"Otu00002", "Otu00003", "Otu00004", "Otu00005", "Otu00006", "Otu00007",
"Otu00008", "Otu00009", "Otu00010", "Otu00011", "Otu00012", "Otu00013",
"Otu00014", "Otu00015", "Otu00016", "Otu00017", "Otu00018", "Otu00019",
"Otu00020", "Otu00021", "Otu00022", "Otu00023", "Otu00024", "Otu00025",
"Otu00026", "Otu00027", "Otu00028", "Otu00029", "Otu00030", "Otu00031",
"Otu00032", "Otu00033", "Otu00034", "Otu00035", "Otu00036", "Otu00037",
"Otu00038", "Otu00039", "Otu00040", "Otu00041", "Otu00042", "Otu00043",
"Otu00044", "Otu00045", "Otu00046", "Otu00047", "Otu00048", "Otu00049",
"Otu00050", "Otu00051", "Otu00052", "Otu00053", "Otu00054", "Otu00055",
"Otu00056", "Otu00057", "Otu00058", "Otu00059", "Otu00060"
),
class = "factor"
)
),
class = "data.frame", row.names = c(NA, -60L)
)
# get_feature_importance
test_that("feature importances are correct", {
expect_equal(get_feature_importance(
trained_model_sm1,
train_data_sm,
test_data_sm,
"dx",
"cancer"
), feat_imps)
})
?future.apply::future_apply
feat_imps
get_feature_importance(
trained_model_sm1,
train_data_sm,
test_data_sm,
"dx",
"cancer"
) %>% dput()
feat_imps <- structure(list(auc = c(0.7955, 0.9065, 0.9045, 0.9, 0.9, 0.9,
0.8815, 0.906, 0.9465, 0.8935, 0.927, 0.9295, 0.9, 0.9085, 0.903,
0.903, 0.9105, 0.903, 0.8975, 0.803, 0.907, 0.9, 0.9, 0.9, 0.93,
0.8875, 0.938, 0.9005, 0.9, 0.9035, 0.9, 0.9, 0.9085, 0.8395,
0.9045, 0.882, 0.9035, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,
0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,
0.9, 0.9), auc_diff = c(0.1045, -0.00649999999999999, -0.00449999999999999,
0, 0, 0, 0.0185, -0.00599999999999997, -0.0465, 0.00650000000000001,
-0.027, -0.0295, 0, -0.00849999999999999, -0.003, -0.003, -0.0105,
-0.00299999999999999, 0.00250000000000001, 0.097, -0.00699999999999997,
0, 0, 0, -0.03, 0.0125, -0.038, -0.00049999999999999, 0, -0.0035,
0, 0, -0.00849999999999999, 0.0605, -0.00449999999999999, 0.018,
-0.0035, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9.99315105491838e-18,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), names = structure(1:60, .Label = c("Otu00001",
"Otu00002", "Otu00003", "Otu00004", "Otu00005", "Otu00006", "Otu00007",
"Otu00008", "Otu00009", "Otu00010", "Otu00011", "Otu00012", "Otu00013",
"Otu00014", "Otu00015", "Otu00016", "Otu00017", "Otu00018", "Otu00019",
"Otu00020", "Otu00021", "Otu00022", "Otu00023", "Otu00024", "Otu00025",
"Otu00026", "Otu00027", "Otu00028", "Otu00029", "Otu00030", "Otu00031",
"Otu00032", "Otu00033", "Otu00034", "Otu00035", "Otu00036", "Otu00037",
"Otu00038", "Otu00039", "Otu00040", "Otu00041", "Otu00042", "Otu00043",
"Otu00044", "Otu00045", "Otu00046", "Otu00047", "Otu00048", "Otu00049",
"Otu00050", "Otu00051", "Otu00052", "Otu00053", "Otu00054", "Otu00055",
"Otu00056", "Otu00057", "Otu00058", "Otu00059", "Otu00060"), class = "factor")), class = "data.frame", row.names = c(NA,
-60L))
# get_feature_importance
test_that("feature importances are correct", {
expect_equal(get_feature_importance(
trained_model_sm1,
train_data_sm,
test_data_sm,
"dx",
"cancer"
), feat_imps)
})
devtools::test()
options(
warnPartialMatchArgs = FALSE,
warnPartialMatchAttr = FALSE,
warnPartialMatchDollar = FALSE
)
get_all_but_model <- function(ml_results) {
return(ml_results[names(ml_results) != "trained_model"])
}
expect_equal_ml_results <- function(result1, result2, tol = 1e-5) {
return(
eval(bquote(expect_equal(get_all_but_model(result1),
get_all_but_model(result2),
tolerance = tol
)))
)
}
test_that("run_ml works for L2 logistic regression", {
expect_equal_ml_results(
run_ml(otu_small,
"regLogistic",
outcome_colname = "dx",
outcome_value = "cancer",
hyperparameters = mikRopML::default_hyperparams,
find_feature_importance = FALSE,
seed = 2019
),
otu_sm_results1
)
expect_equal_ml_results(
run_ml(otu_mini,
"regLogistic",
outcome_colname = "dx",
outcome_value = "cancer",
hyperparameters = mikRopML::test_hyperparams,
find_feature_importance = FALSE,
seed = 2019,
kfold = as.integer(2)
),
otu_mini_results1
)
})
source('~/Desktop/mikRopML/tests/testthat/test-run_ml.R', echo=TRUE)
devtools::test()
test_that("check_kfold works", {
expect_true(is.null(check_kfold(as.integer(1), test_df)))
expect_true(is.null(check_kfold(1, test_df)))
expect_error(
check_kfold(as.integer(10), test_df),
"`kfold` must be an integer"
)
expect_error(
check_kfold(as.integer(0), test_df),
"`kfold` must be an integer"
)
expect_error(
check_kfold("not_an_int", test_df),
"`kfold` must be an integer"
)
})
source('~/Desktop/mikRopML/tests/testthat/test-checks.R', echo=TRUE)
test_that("check_kfold works", {
expect_true(is.null(check_kfold(as.integer(1), test_df)))
expect_true(is.null(check_kfold(1, test_df)))
expect_error(
check_kfold(as.integer(10), test_df),
"`kfold` must be an integer"
)
expect_error(
check_kfold(as.integer(0), test_df),
"`kfold` must be an integer"
)
expect_error(
check_kfold("not_an_int", test_df),
"`kfold` must be an integer"
)
})
devtools::check()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
eval = FALSE
)
knitr::include_graphics("mikRopML-pipeline.pdf")
devtools::build_vignettes()
rmarkdown::render()
rmarkdown::render('vignettes/paper.Rmd')
list.files('vignettes/')
knitr::include_graphics("./vignettes/mikRopML-pipeline.pdf")
knitr::include_graphics("mikRopML-pipeline.pdf")
knitr::include_graphics("vignettes/mikRopML-pipeline.pdf")
rmarkdown::render('vignettes/paper.Rmd')
knitr::include_graphics("mikRopML-pipeline.png")
rmarkdown::render('vignettes/paper.Rmd')
devtools::build_vignettes()
knitr::include_graphics("vignettes/mikRopML-pipeline.png")
knitr::include_graphics("mikRopML-pipeline.png")
