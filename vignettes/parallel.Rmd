---
title: "Parallel processing"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parallel processing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(future.supportsMulticore.unstable = FALSE)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE
)
```

```{r setup}
library(mikropml)
library(future.apply)
```

## Speed up single runs

By default, `preprocess_data()` and `run_ml()` use only one process in series.
If you'd like to parallelize various steps of the pipeline to make them run faster,
install `foreach`, `future`, `future.apply`, and `doFuture`.
Then, register a future plan prior to calling `preprocess_data()` and `run_ml()`.

```{r single}
doFuture::registerDoFuture()
future::plan(future::multicore, workers = 2)
otu_data_preproc <- preprocess_data(otu_small, 'dx')$dat_transformed
result1 <- run_ml(otu_data_preproc, 'regLogistic', seed = 2019)
```

Above, we used the `multicore` plan to split the work across 2 cores.
See the [`future` documentation](https://cran.r-project.org/web/packages/future/vignettes/future-1-overview.html) 
for more about picking the best plan for your use case.
Notably, `multicore` does not work inside RStudio or on Windows;
you will need to use `multisession` instead in those cases.

## Call `run_ml()` multiple times in parallel in R

You can use functions from the `future.apply` package to call 
`run_ml()` multiple times in parallel with different parameters.
You will first need to run `future::plan()` as above if you haven't already.
Then, call `run_ml()` with multiple seeds using `future_lapply()`:

```{r multi_seeds}
results_multi <- future_lapply(seq(100, 104), function(seed) {
  run_ml(otu_data_preproc, 'regLogistic', seed = seed)
  })
```

Each call to `run_ml()` with a different seed uses a different random split 
of the data into training and testing sets.
This example uses only 5 seeds for speed and simplicity,
but for real data we recommend using many more seeds to get a better estimate 
of model performance.

Extract the performance results and combine into one dataframe for all seeds:

```{r bind_multi_seeds}
perf_df <- future_lapply(results_multi, function(result) {
  result[['performance']]
  }) %>% 
  dplyr::bind_rows()
perf_df
```

### Multiple ML methods

You may also wish to compare performance for different ML methods.
`mapply()` can iterate over multiple lists or vectors, 
and `future_mapply()` works the same way:

```{r multi_methods_seeds}
# NOTE: use more seeds for real-world data
param_grid <- expand.grid(seeds = seq(100, 104),
                          methods = c('regLogistic', 'rf'))
results_mtx <- future_mapply(function(seed, method) {
                             run_ml(otu_data_preproc, method, seed = seed)
                             },
                             param_grid$seeds, 
                             param_grid$methods)
```

Extract and combine the performance results for all seeds and methods:

```{r bind_multi_methods}
perf_df2 <- dplyr::bind_rows(results_mtx['performance',])
perf_df2
```

Visualize the performance results:

<!-- TODO: set eval=TRUE once plot_performance() is merged into master -->
```{r plot_perf, eval=FALSE}
plot_performance(perf_df2)
```

## Parallelizing with Snakemake

When parallelizing multiple calls to `run_ml()` in R as in the examples above, 
all of the results objects are held in memory.
This isn't a big deal for a small dataset run with only a few seeds.
However, for large datasets run in parallel with, say, 100 seeds (recommended), 
you may run into problems trying to store all of those objects in memory at once.
One solution is to write the results files of each `run_ml()` call,
then concatenate them at the end.
We show one way to accomplish this with Snakemake; for details see the vignette: 
[Managing mikropml Workflows with Snakemake](snakemake.html).
