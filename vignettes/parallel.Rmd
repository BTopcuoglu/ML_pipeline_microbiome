---
title: "Parallel processing"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parallel processing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(future.supportsMulticore.unstable = FALSE)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE
)
```

```{r setup}
library(mikropml)
```

## Speed up `run_ml()`

By default, `preprocess_data()` and `run_ml()` use only one process in series.

```{r series1}
otu_data_preproc <- preprocess_data(otu_small, 'dx')$dat_transformed
result1 <- run_ml(otu_data_preproc, 'regLogistic', seed = 2019)
```

If you'd like to parallelize various steps of the pipeline,
install `foreach`, `future`, `future.apply`, and `doFuture`.
Then, register a future plan prior to calling `run_ml()`.

```{r parallel1}
doFuture::registerDoFuture()
future::plan(future::multicore, workers = 2)
otu_data_preproc <- preprocess_data(otu_small, 'dx')$dat_transformed
result1 <- run_ml(otu_data_preproc, 'regLogistic', seed = 2019)
```

Above, we used the `multicore` plan to split the work across 2 cores.
See the [`future` documentation](https://cran.r-project.org/web/packages/future/vignettes/future-1-overview.html) 
for more about picking the best plan for your use case.
Notably, `multicore` does not work inside RStudio or on Windows;
you will need to use `multisession` instead in those cases.

## Call `run_ml()` multiple times in parallel

You can use functions from the `future.apply` package to call 
`run_ml()` multiple times in parallel with different parameters.

```{r load_future_apply}
# install.packages('future.apply')
library(future.apply)
```

You will first need to run `future::plan()` as above if you haven't already.
Then, call `run_ml()` with multiple seeds using `future_lapply()`:

```{r multi_seeds}
results_multi <- future_lapply(seq(100, 104), function(seed) {
  run_ml(otu_small, 'regLogistic', seed = seed)
  })
```

Each call to `run_ml()` with a different seed uses a different random split 
of the data into training and testing sets.
This example uses only 5 seeds for speed and simplicity,
but for real data we recommend using many more seeds to get a better estimate 
of model performance.

Extract the performance results and combine into one dataframe for all seeds:

```{r bind_results}
perf_df <- future_lapply(results_multi, function(result) {
  result[['performance']]
  }) %>% 
  dplyr::bind_rows()
perf_df
```

### Multiple ML methods

You may also wish to compare performance for different ML methods.
`mapply()` can iterate over multiple lists or vectors, 
and `future_mapply()` works the same way:

```{r multi_methods_seeds}
# NOTE: use more seeds for real-world data
param_grid <- expand.grid(seeds = seq(100, 104),
                          methods = c('regLogistic', 'rf'))
results_mtx <- future_mapply(function(seed, method) {
                             run_ml(otu_small, method, seed = seed)
                             },
                             param_grid$seeds, 
                             param_grid$methods)
```

Extract and combine the performance results for all seeds and methods:

```{r bind_results_all}
perf_df2 <- dplyr::bind_rows(results_mtx['performance',])
perf_df2
```

Visualize the performance results:

<!-- TODO: set eval=TRUE once plot_performance() is merged into master -->
```{r plot_perf, eval=FALSE}
plot_performance(perf_df2)
```

