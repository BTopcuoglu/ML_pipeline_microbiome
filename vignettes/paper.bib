@misc{fisher2018models,
    title={All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously},
    author={Aaron Fisher and Cynthia Rudin and Francesca Dominici},
    year={2018},
    eprint={1801.01489},
    archivePrefix={arXiv},
    primaryClass={stat.ME}
}

@article{breiman_random_2001,
	title = {Random Forests},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	pages = {5--32},
	number = {1},
	journaltitle = {Machine Learning},
	shortjournal = {Machine Learning},
	author = {Breiman, Leo},
	date = {2001-10-01}
}

@article{wiens_no_2019,
	title = {Do no harm: a roadmap for responsible machine learning for health care},
	volume = {25},
	issn = {1546-170X},
	doi = {10.1038/s41591-019-0548-6},
	shorttitle = {Do no harm},
	abstract = {Interest in machine-learning applications within medicine has been growing, but few studies have progressed to deployment in patient care. We present a framework, context and ultimately guidelines for accelerating the translation of machine-learning-based interventions in health care. To be successful, translation will require a team of engaged stakeholders and a systematic process from beginning (problem formulation) to end (widespread deployment).},
	pages = {1337--1340},
	number = {9},
	journaltitle = {Nature Medicine},
	shortjournal = {Nat. Med.},
	author = {Wiens, Jenna and Saria, Suchi and Sendak, Mark and Ghassemi, Marzyeh and Liu, Vincent X. and Doshi-Velez, Finale and Jung, Kenneth and Heller, Katherine and Kale, David and Saeed, Mohammed and Ossorio, Pilar N. and Thadaney-Israni, Sonoo and Goldenberg, Anna},
	date = {2019},
	pmid = {31427808},
	keywords = {Clinical Decision-Making, Delivery of Health Care, Humans, Machine Learning}
}

@article{teschendorff_avoiding_2019,
	title = {Avoiding common pitfalls in machine learning omic data science},
	volume = {18},
	copyright = {2018 Springer Nature Limited},
	issn = {1476-4660},
	url = {http://www.nature.com/articles/s41563-018-0241-z},
	doi = {10.1038/s41563-018-0241-z},
	abstract = {This Comment describes some of the common pitfalls encountered in deriving and validating predictive statistical models from high-dimensional data. It offers a fresh perspective on some key statistical issues, providing some guidelines to avoid pitfalls, and to help unfamiliar readers better assess the reliability and significance of their results.},
	language = {en},
	number = {5},
	urldate = {2020-08-26},
	journal = {Nature Materials},
	author = {Teschendorff, Andrew E.},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Nature Publishing Group},
	pages = {422--427}
}

@misc{tang_fiddle_2020,
	title = {{FIDDLE}},
	url = {https://gitlab.eecs.umich.edu/mld3/FIDDLE},
	abstract = {FlexIble Data-Driven pipeLinE – a preprocessing pipeline that transforms structured EHR data into feature vectors to be used with ML algorithms},
	language = {en},
	urldate = {2020-08-12},
	journal = {GitLab},
	author = {Tang, Shengpu and Wiens, Jenna},
	year = {2020},
	annote = {TODO: download the actual paper once it's published}
}

@article{topcuoglu_framework_2020,
	title = {A {Framework} for {Effective} {Application} of {Machine} {Learning} to {Microbiome}-{Based} {Classification} {Problems}},
	volume = {11},
	copyright = {Copyright © 2020 Topçuoğlu et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license.},
	issn = {2150-7511},
	url = {https://mbio.asm.org/content/11/3/e00434-20},
	doi = {10.1128/mBio.00434-20},
	abstract = {Machine learning (ML) modeling of the human microbiome has the potential to identify microbial biomarkers and aid in the diagnosis of many diseases such as inflammatory bowel disease, diabetes, and colorectal cancer. Progress has been made toward developing ML models that predict health outcomes using bacterial abundances, but inconsistent adoption of training and evaluation methods call the validity of these models into question. Furthermore, there appears to be a preference by many researchers to favor increased model complexity over interpretability. To overcome these challenges, we trained seven models that used fecal 16S rRNA sequence data to predict the presence of colonic screen relevant neoplasias (SRNs) (n = 490 patients, 261 controls and 229 cases). We developed a reusable open-source pipeline to train, validate, and interpret ML models. To show the effect of model selection, we assessed the predictive performance, interpretability, and training time of L2-regularized logistic regression, L1- and L2-regularized support vector machines (SVM) with linear and radial basis function kernels, a decision tree, random forest, and gradient boosted trees (XGBoost). The random forest model performed best at detecting SRNs with an area under the receiver operating characteristic curve (AUROC) of 0.695 (interquartile range [IQR], 0.651 to 0.739) but was slow to train (83.2 h) and not inherently interpretable. Despite its simplicity, L2-regularized logistic regression followed random forest in predictive performance with an AUROC of 0.680 (IQR, 0.625 to 0.735), trained faster (12 min), and was inherently interpretable. Our analysis highlights the importance of choosing an ML approach based on the goal of the study, as the choice will inform expectations of performance and interpretability.
IMPORTANCE Diagnosing diseases using machine learning (ML) is rapidly being adopted in microbiome studies. However, the estimated performance associated with these models is likely overoptimistic. Moreover, there is a trend toward using black box models without a discussion of the difficulty of interpreting such models when trying to identify microbial biomarkers of disease. This work represents a step toward developing more-reproducible ML practices in applying ML to microbiome research. We implement a rigorous pipeline and emphasize the importance of selecting ML models that reflect the goal of the study. These concepts are not particular to the study of human health but can also be applied to environmental microbiology studies.},
	language = {en},
	number = {3},
	urldate = {2020-07-09},
	journal = {mBio},
	author = {Topçuoğlu, Begüm D. and Lesniak, Nicholas A. and Ruffin, Mack T. and Wiens, Jenna and Schloss, Patrick D.},
	month = jun,
	year = {2020},
	pmid = {32518182},
	note = {Publisher: American Society for Microbiology
Section: Research Article},
	file = {Topçuoğlu_et_al_2020_mBio.pdf:/Users/zenalapp/Zotero/storage/LQNE87HC/Topçuoğlu_et_al_2020_mBio.pdf:application/pdf}
}

@article{pasolli_machine_2016,
	title = {Machine {Learning} {Meta}-analysis of {Large} {Metagenomic} {Datasets}: {Tools} and {Biological} {Insights}},
	volume = {12},
	issn = {1553-7358},
	shorttitle = {Machine {Learning} {Meta}-analysis of {Large} {Metagenomic} {Datasets}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004977},
	doi = {10.1371/journal.pcbi.1004977},
	abstract = {Shotgun metagenomic analysis of the human associated microbiome provides a rich set of microbial features for prediction and biomarker discovery in the context of human diseases and health conditions. However, the use of such high-resolution microbial features presents new challenges, and validated computational tools for learning tasks are lacking. Moreover, classification rules have scarcely been validated in independent studies, posing questions about the generality and generalization of disease-predictive models across cohorts. In this paper, we comprehensively assess approaches to metagenomics-based prediction tasks and for quantitative assessment of the strength of potential microbiome-phenotype associations. We develop a computational framework for prediction tasks using quantitative microbiome profiles, including species-level relative abundances and presence of strain-specific markers. A comprehensive meta-analysis, with particular emphasis on generalization across cohorts, was performed in a collection of 2424 publicly available metagenomic samples from eight large-scale studies. Cross-validation revealed good disease-prediction capabilities, which were in general improved by feature selection and use of strain-specific markers instead of species-level taxonomic abundance. In cross-study analysis, models transferred between studies were in some cases less accurate than models tested by within-study cross-validation. Interestingly, the addition of healthy (control) samples from other studies to training sets improved disease prediction capabilities. Some microbial species (most notably Streptococcus anginosus) seem to characterize general dysbiotic states of the microbiome rather than connections with a specific disease. Our results in modelling features of the “healthy” microbiome can be considered a first step toward defining general microbial dysbiosis. The software framework, microbiome profiles, and metadata for thousands of samples are publicly available at http://segatalab.cibio.unitn.it/tools/metaml.},
	language = {en},
	number = {7},
	urldate = {2020-08-04},
	journal = {PLOS Computational Biology},
	author = {Pasolli, Edoardo and Truong, Duy Tin and Malik, Faizan and Waldron, Levi and Segata, Nicola},
	month = jul,
	year = {2016},
	note = {Publisher: Public Library of Science},
	keywords = {Microbiome, Metagenomics, Species diversity, Forecasting, Type 2 diabetes, Machine learning, Cirrhosis, Obesity},
	pages = {e1004977},
	file = {Pasolli_et_al_2016_PLOS_Computational_Biology.pdf:/Users/zenalapp/Zotero/storage/YLN2F6RT/Pasolli_et_al_2016_PLOS_Computational_Biology.pdf:application/pdf}
}

@article{lapp_machine_2020,
	title = {Machine learning models to identify patient and microbial genetic factors associated with carbapenem-resistant {Klebsiella} pneumoniae infection},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2020.07.06.20147306v1},
	doi = {10.1101/2020.07.06.20147306},
	abstract = {{\textless}p{\textgreater}Wurtzite boron nitride (w-BN) is a metastable superhard material that is a high-pressure polymorph of BN. Clarifying how the metastable high-pressure material can be stabilized at atmospheric pressure is a challenging issue of fundamental scientific importance and promising technological value. Here, we fabricate millimeter-size w-BN bulk crystals via the hexagonal-to-wurtzite phase transformation at high pressure and high temperature. By combining transmission electron microscopy and ab initio molecular dynamics simulations, we reveal a stabilization mechanism for w-BN, i.e., the metastable high-pressure phase can be stabilized by 3D networks of planar defects which are constructed by a high density of intersecting (0001) stacking faults and \{10{\textless}math xmlns="http://www.w3.org/1998/Math/MathML" id="i1" overflow="scroll"{\textgreater}{\textless}mrow{\textgreater}{\textless}mover accent="true"{\textgreater}{\textless}mn{\textgreater}1{\textless}/mn{\textgreater}{\textless}mo stretchy="true"{\textgreater}¯{\textless}/mo{\textgreater}{\textless}/mover{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater}0\} inversion domain boundaries. The 3D networks of planar defects segment the w-BN bulk crystal into numerous nanometer-size prismatic domains with the reverse crystallographic polarities. Our findings unambiguously demonstrate the retarding effect of crystal defects on the phase transformations of metastable materials, which is in contrast to the common knowledge that the crystal defects in materials will facilitate the occurrence of phase transformations.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-08-26},
	journal = {medRxiv},
	author = {Lapp, Zena and Han, Jennifer and Wiens, Jenna and Goldstein, Ellie JC and Lautenbach, Ebbing and Snitkin, Evan},
	month = jul,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
	pages = {2020.07.06.20147306},
	file = {Full Text PDF:/Users/zenalapp/Zotero/storage/6CJMUXVB/Lapp et al. - 2020 - Machine learning models to identify patient and mi.pdf:application/pdf;Snapshot:/Users/zenalapp/Zotero/storage/DHVUDBXT/2020.07.06.html:text/html}
}

@article{kuhn_building_2008,
	title = {Building {Predictive} {Models} in {R} {Using} the caret {Package}},
	volume = {28},
	copyright = {Copyright (c) 2008 Max Kuhn},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v028i05},
	doi = {10.18637/jss.v028.i05},
	language = {en},
	number = {1},
	urldate = {2020-08-26},
	journal = {Journal of Statistical Software},
	author = {Kuhn, Max},
	month = nov,
	year = {2008},
	note = {Number: 1},
	pages = {1--26},
	file = {Full Text:/Users/zenalapp/Zotero/storage/5ASXWNJC/Kuhn - 2008 - Building Predictive Models in R Using the caret Pa.pdf:application/pdf;Snapshot:/Users/zenalapp/Zotero/storage/JEL8LDQ8/v028i05.html:text/html}
}

@article{grau_prroc_2015,
	title = {{PRROC}: computing and visualizing precision-recall and receiver operating characteristic curves in {R}},
	volume = {31},
	issn = {1367-4803},
	shorttitle = {{PRROC}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4514923/},
	doi = {10.1093/bioinformatics/btv153},
	abstract = {Summary: Precision-recall (PR) and receiver operating characteristic (ROC) curves are valuable measures of classifier performance. Here, we present the R-package PRROC, which allows for computing and visualizing both PR and ROC curves. In contrast to available R-packages, PRROC allows for computing PR and ROC curves and areas under these curves for soft-labeled data using a continuous interpolation between the points of PR curves. In addition, PRROC provides a generic plot function for generating publication-quality graphics of PR and ROC curves., Availability and implementation: PRROC is available from CRAN and is licensed under GPL 3., Contact: grau@informatik.uni-halle.de},
	number = {15},
	urldate = {2020-08-26},
	journal = {Bioinformatics},
	author = {Grau, Jan and Grosse, Ivo and Keilwagen, Jens},
	month = aug,
	year = {2015},
	pmid = {25810428},
	pmcid = {PMC4514923},
	pages = {2595--2597},
	file = {PubMed Central Full Text PDF:/Users/zenalapp/Zotero/storage/FVUX9WXH/Grau et al. - 2015 - PRROC computing and visualizing precision-recall .pdf:application/pdf}
}

@article{wickham_welcome_2019,
	title = {Welcome to the {Tidyverse}},
	volume = {4},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.01686},
	doi = {10.21105/joss.01686},
	abstract = {Wickham et al., (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686},
	language = {en},
	number = {43},
	urldate = {2020-08-26},
	journal = {Journal of Open Source Software},
	author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
	month = nov,
	year = {2019},
	pages = {1686},
	file = {Full Text PDF:/Users/zenalapp/Zotero/storage/5JHFL8AP/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf:application/pdf;Snapshot:/Users/zenalapp/Zotero/storage/AK534V5U/joss.html:text/html}
}

@misc{r_core_team_r_2020,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2020}
}

@misc{paul_liblinear_2017,
	title = {{LiblineaR}: {Linear} {Predictive} {Models} {Based} on the '{LIBLINEAR}' {C}/{C}++ {Library}},
	copyright = {GPL-2},
	shorttitle = {{LiblineaR}},
	url = {https://CRAN.R-project.org/package=LiblineaR},
	abstract = {A wrapper around the 'LIBLINEAR' C/C++ library for machine learning (available at {\textless}http://www.csie.ntu.edu.tw/{\textasciitilde}cjlin/liblinear{\textgreater}). 'LIBLINEAR' is a simple library for solving large-scale regularized linear classification and regression. It currently supports L2-regularized classification (such as logistic regression, L2-loss linear SVM and L1-loss linear SVM) as well as L1-regularized classification (such as L2-loss linear SVM and logistic regression) and L2-regularized support vector regression (with L1- or L2-loss). The main features of LiblineaR include multi-class classification (one-vs-the rest, and Crammer \& Singer method), cross validation for model selection, probability estimates (logistic regression only) or weights for unbalanced data. The estimation of the models is particularly fast as compared to other libraries.},
	urldate = {2020-08-26},
	author = {Paul, Thibault Helleputte; Pierre Gramme; Jerome},
	month = feb,
	year = {2017},
	keywords = {MachineLearning}
}

@misc{wickham_dplyr_2020,
	title = {dplyr: {A} {Grammar} of {Data} {Manipulation}},
	copyright = {MIT + file LICENSE},
	shorttitle = {dplyr},
	url = {https://CRAN.R-project.org/package=dplyr},
	abstract = {A fast, consistent tool for working with data frame like objects, both in memory and out of memory.},
	urldate = {2020-08-26},
	author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill and RStudio},
	month = aug,
	year = {2020},
	keywords = {Databases, ModelDeployment}
}

@misc{henry_rlang_2020,
	title = {rlang: {Functions} for {Base} {Types} and {Core} {R} and '{Tidyverse}' {Features}},
	copyright = {GPL-3},
	shorttitle = {rlang},
	url = {https://CRAN.R-project.org/package=rlang},
	abstract = {A toolbox for working with base types, core R features like the condition system, and core 'Tidyverse' features like tidy evaluation.},
	urldate = {2020-08-26},
	author = {Henry, Lionel and Wickham, Hadley and RStudio},
	month = jul,
	year = {2020}
}

@article{wickham_testthat_2011,
	title = {testthat: {Get} {Started} with {Testing}},
	volume = {3},
	issn = {2073-4859},
	shorttitle = {testthat},
	url = {https://journal.r-project.org/archive/2011/RJ-2011-002/index.html},
	doi = {10.32614/RJ-2011-002},
	abstract = {Software testing is important, but many of us don’t do it because it is frustrating and boring. testthat is a new testing framework for R that is easy learn and use, and integrates with your existing workﬂow. This paper shows how, with illustrations from existing packages.},
	language = {en},
	number = {1},
	urldate = {2020-08-26},
	journal = {The R Journal},
	author = {Wickham, Hadley},
	year = {2011},
	pages = {5},
	file = {Wickham - 2011 - testthat Get Started with Testing.pdf:/Users/zenalapp/Zotero/storage/HUUMA8LX/Wickham - 2011 - testthat Get Started with Testing.pdf:application/pdf}
}

@book{xie_dynamic_2015,
	title = {Dynamic {Documents} with {R} and {Knitr}},
	isbn = {978-1-4987-8739-0},
	abstract = {Quickly and Easily Write Dynamic Documents Suitable for both beginners and advanced users, Dynamic Documents with R and knitr, Second Edition makes writing statistical reports easier by integrating computing directly with reporting. Reports range from homework, projects, exams, books, blogs, and web pages to virtually any documents related to statistical graphics, computing, and data analysis. The book covers basic applications for beginners while guiding power users in understanding the extensibility of the knitr package.},
	language = {en},
	publisher = {CRC Press},
	author = {Xie, Yihui},
	year = {2015},
	note = {Google-Books-ID: C1ZdswEACAAJ},
	keywords = {MATHEMATICS / Probability \& Statistics / General}
}

@misc{xie__aut_knitr_2020,
	title = {knitr: {A} {General}-{Purpose} {Package} for {Dynamic} {Report} {Generation} in {R}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL]},
	shorttitle = {knitr},
	url = {https://CRAN.R-project.org/package=knitr},
	abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
	urldate = {2020-08-26},
	author = {Xie  [aut, Yihui and cre and Vogt, Adam and Andrew, Alastair and Zvoleff, Alex and http://www.andre-simon.de), Andre Simon (the CSS files under inst/themes/ were derived from the Highlight package and Atkins, Aron and Wolen, Aaron and Manton, Ashley and Yasumoto, Atsushi and Baumer, Ben and Diggs, Brian and Zhang, Brian and Pereira, Cassio and Dervieux, Christophe and Hugh-Jones, David and Robinson, David and Hemken, Doug and Murdoch, Duncan and Campitelli, Elio and Hughes, Ellis and Riederer, Emily and Hirschmann, Fabian and Simeon, Fitch and Fang, Forest and inst/misc/Sweavel.sty), Frank E. Harrell Jr (the Sweavel package at and Aden-Buie, Garrick and Detrez, Gregoire and Wickham, Hadley and Zhu, Hao and Jeon, Heewon and Bengtsson, Henrik and Yutani, Hiroaki and Lyttle, Ian and Daniel, Hodges and Burkhead, Jake and Manton, James and Lander, Jared and Punyon, Jason and Luraschi, Javier and Arnold, Jeff and Bryan, Jenny and inst/misc/docco-classic.css), Jeremy Ashkenas (the CSS file at and Stephens, Jeremy and Hester, Jim and Cheng, Joe and Ranke, Johannes and Honaker, John and Muschelli, John and Keane, Jonathan and Allaire, J. J. and Toloe, Johan and Sidi, Jonathan and Larmarange, Joseph and Barnier, Julien and Zhong, Kaiyin and Slowikowski, Kamil and Forner, Karl and Smith, Kevin K. and Mueller, Kirill and Takahashi, Kohske and Walthert, Lorenz and Gallindo, Lucas and Hofert, Marius and Modrák, Martin and Chirico, Michael and Friendly, Michael and Bojanowski, Michal and Kuhlmann, Michel and Patrick, Miller and Caballero, Nacho and Salkowski, Nick and Hansen, Niels Richard and Ross, Noam and Mahdi, Obada and Li, Qiang and Vaidyanathan, Ramnath and Cotton, Richard and Krzyzanowski, Robert and Francois, Romain and Williamson, Ruaridh and Kostyshak, Scott and Meyer, Sebastian and Brouwer, Sietse and Bernard, Simon de and Rousseau, Sylvain and Wei, Taiyun and Assus, Thibaut and Lamadon, Thibaut and Leeper, Thomas and Mastny, Tim and Torsney-Weir, Tom and Davis, Trevor and Veitas, Viktoras and Zhu, Weicheng and Wu, Wush and Foster, Zachary},
	month = jun,
	year = {2020},
	keywords = {ReproducibleResearch}
}

@misc{allaire_rmarkdown_2020,
	title = {rmarkdown: {Dynamic} {Documents} for {R}},
	copyright = {GPL-3},
	shorttitle = {rmarkdown},
	url = {https://CRAN.R-project.org/package=rmarkdown},
	abstract = {Convert R Markdown documents into a variety of formats.},
	urldate = {2020-08-26},
	author = {Allaire, J. J. and Xie  [aut, Yihui and cre and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard and Dunning, Andrew and Yasumoto, Atsushi and Schloerke, Barret and Dervieux, Christophe and Aust, Frederik and Allen, Jeff and Seo, JooYoung and Barrett, Malcolm and Hyndman, Rob and Lesur, Romain and Storey, Roy and Arslan, Ruben and Oller, Sergio and RStudio and PBC and library), jQuery Foundation (jQuery and inst/rmd/h/jquery-AUTHORS.txt), jQuery contributors (jQuery library; authors listed in and inst/rmd/h/jqueryui-AUTHORS.txt), jQuery UI contributors (jQuery UI library; authors listed in and library), Mark Otto (Bootstrap and library), Jacob Thornton (Bootstrap and library), Bootstrap contributors (Bootstrap and Twitter and library), Inc (Bootstrap and library), Alexander Farkas (html5shiv and library), Scott Jehl (Respond js and library), Ivan Sagalaev (highlight js and library), Greg Franko (tocify and templates), John MacFarlane (Pandoc and Google and library), Inc (ioslides and library), Dave Raggett (slidy and library), W3C (slidy and Gandy  (Font-Awesome), Dave and Sperry  (Ionicons), Ben and Drifty (Ionicons) and StickyTabs), Aidan Lister (jQuery and filter), Benct Philip Jonsson (pagebreak lua and filter), Albert Krewinkel (pagebreak lua},
	month = jun,
	year = {2020},
	keywords = {ReproducibleResearch}
}

@book{xie_r_2018,
	title = {R {Markdown}: {The} {Definitive} {Guide}},
	isbn = {978-1-138-35933-8},
	shorttitle = {R {Markdown}},
	abstract = {R Markdown: The Definitive Guide is the first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages.   In this book, you will learn   Basics: Syntax of Markdown and R code chunks, how to generate figures and tables, and how to use other computing languages    Built-in output formats of R Markdown: PDF/HTML/Word/RTF/Markdown documents and ioslides/Slidy/Beamer/PowerPoint presentations    Extensions and applications: Dashboards, Tufte handouts, xaringan/reveal.js presentations, websites, books, journal articles, and interactive tutorials    Advanced topics: Parameterized reports, HTML widgets, document templates, custom output formats, and Shiny documents.    Yihui Xie is a software engineer at RStudio. He has authored and co-authored several R packages, including knitr, rmarkdown, bookdown, blogdown, shiny, xaringan, and animation. He has published three other books, Dynamic Documents with R and knitr, bookdown: Authoring Books and Technical Documents with R Markdown, and blogdown: Creating Websites with R Markdown.  J.J. Allaire is the founder of RStudio and the creator of the RStudio IDE. He is an author of several packages in the R Markdown ecosystem including rmarkdown, flexdashboard, learnr, and radix.  Garrett Grolemund is the co-author of R for Data Science and author of Hands-On Programming with R. He wrote the lubridate R package and works for RStudio as an advocate who trains engineers to do data science with R and the Tidyverse.},
	language = {en},
	publisher = {Taylor \& Francis, CRC Press},
	author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
	year = {2018},
	note = {Google-Books-ID: j9YyuAEACAAJ}
}

@misc{bengtsson_futureapply_2020,
	title = {future.apply: {Apply} {Function} to {Elements} in {Parallel} using {Futures}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
	shorttitle = {future.apply},
	url = {https://CRAN.R-project.org/package=future.apply},
	abstract = {Implementations of apply(), by(), eapply(), lapply(), Map(), .mapply(), mapply(), replicate(), sapply(), tapply(), and vapply() that can be resolved using any future-supported backend, e.g. parallel on the local machine or distributed on a compute cluster. These future\_*apply() functions come with the same pros and cons as the corresponding base-R *apply() functions but with the additional feature of being able to be processed via the future framework.},
	urldate = {2020-08-26},
	author = {Bengtsson, Henrik and R Core Team},
	month = jul,
	year = {2020}
}

@article{liaw_classication_2002,
	title = {Classiﬁcation and {Regression} by {randomForest}},
	volume = {2},
	language = {en},
	author = {Liaw, Andy and Wiener, Matthew},
	year = {2002},
	pages = {5},
	file = {Liaw and Wiener - 2002 - Classiﬁcation and Regression by randomForest.pdf:/Users/zenalapp/Zotero/storage/HWB86W3X/Liaw and Wiener - 2002 - Classiﬁcation and Regression by randomForest.pdf:application/pdf}
}

@article{karatzoglou_kernlab_2004,
	title = {kernlab - {An} {S4} {Package} for {Kernel} {Methods} in {R}},
	volume = {11},
	copyright = {Copyright (c) 2004 Alexandros Karatzoglou, Alexandros Smola, Kurt Hornik, Achim Zeileis},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v011i09},
	doi = {10.18637/jss.v011.i09},
	language = {en},
	number = {1},
	urldate = {2020-08-26},
	journal = {Journal of Statistical Software},
	author = {Karatzoglou, Alexandros and Smola, Alexandros and Hornik, Kurt and Zeileis, Achim},
	month = nov,
	year = {2004},
	note = {Number: 1},
	pages = {1--20},
	file = {Full Text:/Users/zenalapp/Zotero/storage/PI2FRHXP/Karatzoglou et al. - 2004 - kernlab - An S4 Package for Kernel Methods in R.pdf:application/pdf;Snapshot:/Users/zenalapp/Zotero/storage/QZYZ79FT/v011i09.html:text/html}
}

@misc{therneau_rpart_2019,
	title = {rpart: {Recursive} {Partitioning} and {Regression} {Trees}},
	copyright = {GPL-2 {\textbar} GPL-3},
	shorttitle = {rpart},
	url = {https://CRAN.R-project.org/package=rpart},
	abstract = {Recursive partitioning for classification, regression and survival trees. An implementation of most of the functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.},
	urldate = {2020-08-26},
	author = {Therneau, Terry and Atkinson, Beth and port, Brian Ripley (producer of the initial R. and maintainer 1999-2017)},
	month = apr,
	year = {2019},
	keywords = {Survival, Environmetrics, Multivariate, MachineLearning}
}

@misc{therneau_rpart_2019-1,
	title = {rpart: {Recursive} {Partitioning} and {Regression} {Trees}},
	copyright = {GPL-2 {\textbar} GPL-3},
	shorttitle = {rpart},
	url = {https://CRAN.R-project.org/package=rpart},
	abstract = {Recursive partitioning for classification, regression and survival trees. An implementation of most of the functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.},
	urldate = {2020-08-26},
	author = {Therneau, Terry and Atkinson, Beth and port, Brian Ripley (producer of the initial R. and maintainer 1999-2017)},
	month = apr,
	year = {2019},
	keywords = {Survival, Environmetrics, Multivariate, MachineLearning}
}

@misc{chen_xgboost_2020,
	title = {xgboost: {Extreme} {Gradient} {Boosting}},
	copyright = {Apache License (== 2.0) {\textbar} file LICENSE},
	shorttitle = {xgboost},
	url = {https://CRAN.R-project.org/package=xgboost},
	abstract = {Extreme Gradient Boosting, which is an efficient implementation of the gradient boosting framework from Chen \& Guestrin (2016) {\textless}doi:10.1145/2939672.2939785{\textgreater}. This package is its R interface. The package includes efficient linear model solver and tree learning algorithms. The package can automatically do parallel computation on a single machine which could be more than 10 times faster than existing gradient boosting packages. It supports various objective functions, including regression, classification and ranking. The package is made to be extensible, so that users are also allowed to define their own objectives easily.},
	urldate = {2020-08-26},
	author = {Chen, Tianqi and He, Tong and Benesty, Michael and Khotilovich, Vadim and Tang, Yuan and Cho, Hyunsu and Chen, Kailong and Mitchell, Rory and Cano, Ignacio and Zhou, Tianyi and Li, Mu and Xie, Junyuan and Lin, Min and Geng, Yifeng and Li, Yutian and implementation), XGBoost contributors (base XGBoost},
	month = jun,
	year = {2020},
	keywords = {MachineLearning, ModelDeployment, HighPerformanceComputing}
}

@misc{ooi_doparallel_2019,
	title = {{doParallel}: {Foreach} {Parallel} {Adaptor} for the 'parallel' {Package}},
	copyright = {GPL-2},
	shorttitle = {{doParallel}},
	url = {https://CRAN.R-project.org/package=doParallel},
	abstract = {Provides a parallel backend for the \%dopar\% function using the parallel package.},
	urldate = {2020-08-26},
	author = {Ooi, Hong and Corporation, Microsoft and Weston, Steve and Tenenbaum, Dan},
	month = aug,
	year = {2019}
}

@misc{ooi_foreach_2020,
	title = {foreach: {Provides} {Foreach} {Looping} {Construct}},
	copyright = {Apache License (== 2.0)},
	shorttitle = {foreach},
	url = {https://CRAN.R-project.org/package=foreach},
	abstract = {Support for the foreach looping construct. Foreach is an idiom that allows for iterating over elements in a collection, without the use of an explicit loop counter. This package in particular is intended to be used for its return value, rather than for its side effects. In that sense, it is similar to the standard lapply function, but doesn't require the evaluation of a function. Using foreach without side effects also facilitates executing the loop in parallel.},
	urldate = {2020-08-26},
	author = {Ooi, Hong and Microsoft and Weston, Steve},
	month = mar,
	year = {2020},
	keywords = {HighPerformanceComputing}
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	shorttitle = {Scikit-learn},
	url = {http://jmlr.org/papers/v12/pedregosa11a.html},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	number = {85},
	urldate = {2020-08-26},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	year = {2011},
	pages = {2825--2830},
	file = {Fulltext PDF:/Users/zenalapp/Zotero/storage/XHFW3BLS/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf}
}

@misc{kuhn_tidymodels_2020,
	title = {tidymodels: {Easily} {Install} and {Load} the '{Tidymodels}' {Packages}},
	copyright = {GPL-3 {\textbar} file LICENSE},
	shorttitle = {tidymodels},
	url = {https://CRAN.R-project.org/package=tidymodels},
	abstract = {The tidy modeling "verse" is a collection of packages for modeling and statistical analysis that share the underlying design philosophy, grammar, and data structures of the tidyverse.},
	urldate = {2020-09-09},
	author = {Kuhn, Max and Wickham, Hadley and RStudio},
	month = jul,
	year = {2020}
}

@article{koster_snakemakescalable_2012,
	title = {Snakemake—a scalable bioinformatics workflow engine},
	volume = {28},
	issn = {1367-4803},
	url = {http://academic.oup.com/bioinformatics/article/28/19/2520/290322},
	doi = {10.1093/bioinformatics/bts480},
	abstract = {Abstract.  Summary: Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that},
	language = {en},
	number = {19},
	urldate = {2020-09-09},
	journal = {Bioinformatics},
	author = {Köster, Johannes and Rahmann, Sven},
	month = oct,
	year = {2012},
	note = {Publisher: Oxford Academic},
	pages = {2520--2522},
	file = {Full Text PDF:/Users/zenalapp/Zotero/storage/KAC2BA4Q/Köster and Rahmann - 2012 - Snakemake—a scalable bioinformatics workflow engin.pdf:application/pdf;Snapshot:/Users/zenalapp/Zotero/storage/JH2GHQ5P/290322.html:text/html}
}

@misc{therneau_rpart_2019-2,
	title = {rpart: {Recursive} {Partitioning} and {Regression} {Trees}},
	copyright = {GPL-2 {\textbar} GPL-3},
	shorttitle = {rpart},
	url = {https://CRAN.R-project.org/package=rpart},
	abstract = {Recursive partitioning for classification, regression and survival trees. An implementation of most of the functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.},
	urldate = {2020-09-09},
	author = {Therneau, Terry and Atkinson, Beth and port, Brian Ripley (producer of the initial R. and maintainer 1999-2017)},
	month = apr,
	year = {2019},
	keywords = {Environmetrics, MachineLearning, Multivariate, Survival}
}
